<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<title>Research | Chaymae Bennouri</title>
 <link rel="stylesheet" href="style.css" />
</head>
<body>

  <header>
    <div class="navbar">
        <img src="assets/moi.jpeg" alt="Chaymae Bennouri" class="profile-pic"/>
        <h1>Chaymae Bennouri</h1>
        <h2>R&D Consultant</h2>
        <nav>
          <a href="index.html#about">About</a>
          <a href="index.html#projects">Projects</a>
          <a href="index.html#resume">Resume</a>
          <a class="active" href="research.html">Research</a>
          <a href="index.html#highlights">Highlights</a>
          <a href="index.html#contact">Contact</a>
        </nav>
        <button id="themeToggle" class="dark-toggle" type="button">ðŸŒ™ Toggle Dark Mode</button>
    </div>
  </header>



  <main class="container">
    <section class="page-hero">
      <h1>Research</h1>
      <p class="subtitle">
        My research interests sit at the intersection of applied machine learning, collective intelligence, and robust decision-making under real-world constraints.
      </p>
    </section>

   <section class="card">
  <h3>Effect of Type of Source on Response Change</h3>
  <p class="meta">
    Cognitive Science / Experimental Study (Masterâ€™s level)
  </p>

  <p>
    This experimental study investigates how the type of information source
    (expert vs anonymous) influences participantsâ€™ response changes, confidence
    levels, and trust. The study focuses on belief updating mechanisms when
    individuals are exposed to explanations attributed to sources with differing
    credibility.
  </p>

  <ul>
    <li><strong>Research question:</strong> How does source type affect response change, confidence, and trust?</li>
    <li><strong>Design:</strong> Within-subject experimental design using Qualtrics</li>
    <li><strong>Methods:</strong> Randomization, counterbalancing, confidence and trust scales</li>
    <li><strong>Key variables:</strong> Source type (expert vs anonymous), response accuracy, confidence, trust</li>
    <li><strong>Validity controls:</strong> Block randomization, counterbalancing to reduce order effects</li>
  </ul>

  <p>
    Results indicate higher confidence and greater response change when explanations
    are attributed to expert sources. The study discusses limitations related to
    fatigue, familiarity with questions, and the need for formal statistical testing.
  </p>

  <p class="links">
    <a href="assets/Projects/Effect_of_Type_of_Source_on_Response_Change.pdf" target="_blank"> Full report (PDF)</a>
  </p>
</section>

<section class="card">
  <h3>Relationship Between Personality Traits and Academic Motivation</h3>
  <p class="meta">
    Cognitive Science / Educational Psychology Quantitative Study
  </p>

  <p>
    This study examines the relationship between the Big Five personality traits
    and academic motivation (intrinsic and extrinsic) among university students
    at Mohammed VI Polytechnic University. The objective was to identify which
    personality dimensions are statistically associated with higher levels of
    student motivation.
  </p>

  <ul>
    <li><strong>Research question:</strong> What is the relationship between Big Five personality traits and academic motivation?</li>
    <li><strong>Sample:</strong> 39 university students (after data cleaning)</li>
    <li><strong>Design:</strong> Within-group quantitative study using survey instruments</li>
    <li><strong>Measures:</strong> Big Five personality traits (matrix scale), intrinsic/extrinsic motivation (7-point Likert)</li>
    <li><strong>Analysis:</strong> Normality testing (Shapiroâ€“Wilk), variance testing (Bartlett), ANOVA/Welch tests, logistic regression</li>
  </ul>

  <p>
    Results indicate that <strong>conscientiousness</strong> is the only personality
    trait significantly associated with academic motivation. Logistic regression
    analysis shows that students with conscientious traits are more than twice as
    likely to be motivated compared to those without these traits.
  </p>

  <p>
    The study discusses limitations related to sample size, convenience sampling,
    and generalisability, and highlights the need for replication on a larger and
    more representative population.
  </p>

  <p class="links">
    <a href="assets/Projects/Personality_traits_and_motivation_UM6P.pdf" target="_blank"> Full paper (PDF) </a>
  </p>
</section>

<section class="card">
  <h3>CoLabCareers: Crowd-Based Evaluation of Professional Content</h3>
  <p class="meta">
    Collective Intelligence / Crowd Computing Project (Supervised by Prof. Mark Klein)
  </p>

  <p>
    This project investigates how collective intelligence mechanisms can be used to
    improve the quality and fairness of professional content evaluation in early-career
    job markets. The study explores whether peer-based crowd review can reduce bias,
    encourage constructive feedback, and iteratively improve candidate profiles.
  </p>

  <ul>
    <li><strong>Research question:</strong> How can crowd wisdom be leveraged to evaluate and improve professional content fairly and effectively?</li>
    <li><strong>Approach:</strong> Design and implementation of a crowd-based review platform</li>
    <li><strong>Collective intelligence mechanisms:</strong> Multi-voting, Bag of Stars (BoS), anonymised peer review</li>
    <li><strong>Key design principles:</strong> Anonymity, coopetition, iterative improvement</li>
    <li><strong>Evaluation criteria:</strong> Reliability, user satisfaction, and cost-effectiveness</li>
  </ul>

  <p>
    Results indicate that anonymised crowd review reduces perceived bias related to
    personal attributes (name, gender, nationality) and fosters constructive feedback.
    Peer-generated ratings and comments enabled iterative improvement of submitted
    professional content.
  </p>

  <p>
    Identified limitations include reliance on sustained user engagement, administrative
    moderation requirements, and scalability challenges. Future work proposes integrating
    company feedback, incentive mechanisms, and large-scale data analysis to improve
    robustness and long-term sustainability.
  </p>

  <p class="links">
    <a href="assets/Projects/CoLabcareers.pdf" target="_blank"> Full report (PDF)</a>
  </p>
</section>

<section class="card">
  <h3>Water Connectivity Issues in Rural Morocco</h3>
  <p class="meta">
    Experimental Methods / Causal Inference Field Evaluation Study (UM6P)
  </p>

  <p>
    This study designs and evaluates a policy intervention aimed at improving
    water access in rural Morocco, focusing on 28 rural communes across the
    Provinces of Safi, Youssoufia, and Sidi Bennour. The research addresses
    persistent water scarcity driven by lack of household connections,
    transportation constraints, and poverty.
  </p>

  <ul>
    <li><strong>Research questions:</strong>
      <ul>
        <li>Does a motor-tricycleâ€“based water delivery system improve water access?</li>
        <li>How does improved water access affect subjective well-being and happiness?</li>
        <li>Does water delivery reduce health risks such as waterborne diseases?</li>
      </ul>
    </li>

    <li><strong>Intervention:</strong> Credit-financed motor tricycles for decentralized water delivery</li>
    <li><strong>Design:</strong> Cluster randomized controlled trial (28 communes)</li>
    <li><strong>Methodology:</strong> Encouragement design, ITT and LATE estimation</li>
    <li><strong>Power analysis:</strong> ICC = 0.1, effect size = 0.4, power = 0.8, Î± = 0.05</li>
    <li><strong>Outcomes:</strong> Water consumption, time savings, well-being, school attendance</li>
  </ul>

  <p>
    The evaluation design explicitly accounts for spillovers by randomizing at
    the commune level. The analysis plan includes baseline balance checks,
    descriptive statistics, ITT estimation, covariate adjustment, and sensitivity
    analyses for attrition and compliance.
  </p>

  <p>
    Expected results suggest increased water consumption, reduced time burden,
    improved subjective well-being, and lower school dropout rates, while not
    affecting drinking water quality.
  </p>

  <p class="links">
    <a href="assets/Projects/Water_Connectivity.pdf" target="_blank"> Full report (PDF) </a>
  </p>
</section>

<section class="card">
  <h3>Crowd Forecasting for S&P 500 Trading Decisions</h3>
  <p class="meta">
    Collective Intelligence / Forecast Evaluation Quantitative Study
  </p>

  <p>
    This study evaluates whether collective intelligenceâ€“based forecasting
    strategies can outperform conventional technical indicators in predicting
    short-term movements of the S&P 500 index. The research compares crowd-based
    aggregation methods with traditional trading indicators using accuracy and
    probabilistic performance metrics.
  </p>

  <ul>
    <li><strong>Research question:</strong> Can aggregated crowd forecasts outperform traditional technical indicators in market direction prediction?</li>
    <li><strong>Baseline strategies:</strong> RSI, Moving Average, MACD</li>
    <li><strong>Crowd-based strategies:</strong> Aggregation by share price, trade quantity</li>
    <li><strong>Aggregation models:</strong> Mean and median aggregation of crowd signals</li>
    <li><strong>Evaluation metrics:</strong> Accuracy and Brier score</li>
    <li><strong>Data:</strong> S&P 500 daily trading data (2022)</li>
  </ul>

  <p>
    Results show that conventional technical indicators achieved accuracies
    below 50%, while crowd-based aggregation methods significantly improved
    predictive performance. Median aggregation of crowd forecasts achieved
    the highest performance, with accuracy above 80% and a Brier score of 0.07,
    indicating superior probabilistic calibration.
  </p>

  <p>
    The study highlights the robustness of aggregated human forecasts compared
    to single-indicator strategies and discusses limitations related to crowd
    size, diversity, and temporal stability. Future work proposes integrating
    larger and more diverse forecaster populations and combining crowd signals
    with machine learning models.
  </p>

  <p class="links">
    <a href="assets/Projects/S&P_500.pdf" target="_blank"> Full report (PDF) </a>
  </p>
</section>

<section class="card">
  <h3>Error Analysis of the Vision 2030 Deliberation Map</h3>
  <p class="meta">
    Collective Intelligence / Deliberation Quality Research Internship (Supervised by Prof. Mark Klein)
  </p>

  <p>
    This research internship focused on the systematic analysis of deliberation quality
    within the Vision 2030 question map. The objective was to identify, classify, and
    quantify structural and semantic errors in large-scale participatory deliberation
    data, with the aim of improving the quality, usability, and interpretability of
    collective intelligence outputs.
  </p>

  <ul>
    <li><strong>Research objective:</strong> How can error taxonomy and frequency analysis improve the quality of large-scale deliberation maps?</li>
    <li><strong>Dataset:</strong> 746 user-generated contributions across three themes (Research, Teaching & Student Life, Entrepreneurship & Social Impact)</li>
    <li><strong>Method:</strong> Manual qualitative coding using a predefined error taxonomy</li>
    <li><strong>Error taxonomy:</strong> 9 major error categories with tagged subtypes (e.g. unclear, misplaced, redundant, insubstantive)</li>
    <li><strong>Analysis:</strong> Frequency analysis and cross-category comparison</li>
  </ul>

  <p>
    Results show that nearly half of the contributions were affected by <em>unclear</em>
    errors, primarily due to missing or incomplete titles and descriptions. Other
    frequent issues included misplaced content, redundancy, and insubstantive responses.
    These findings highlight structural weaknesses in unconstrained deliberation
    processes and the need for improved guidance and validation mechanisms.
  </p>

  <p>
    Based on the analysis, the study proposes several improvements, including stricter
    hierarchy enforcement, multi-stage cleaning pipelines, respondent randomization to
    mitigate fatigue, and the potential use of automated or AI-assisted detectors to
    identify low-quality or malformed contributions.
  </p>

  <p class="links">
    <a href="assets/Projects/Vision_2030.pdf" target="_blank"> Internship report (PDF) </a>
  </p>
</section>


  </main>
  <footer>
    <div class="container">
     <p>Thank you for visiting my portfolio! Feel free to reach out if you have any questions or opportunities.</p>
     <p>Â© 2025 Chaymae Bennouri</p>
   </div>
</footer>
  <script src="script.js"></script>
</body>
</html>